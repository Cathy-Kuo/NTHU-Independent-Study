{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    \n",
    "    def __init__(self , num_state , num_action):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.gc1 = GraphConvolution(num_state, 64)\n",
    "        self.gc6 = GraphConvolution(64, num_action)\n",
    "        self.out = nn.Linear(num_action , 1)\n",
    "        \n",
    "    def forward(self , x, adj):\n",
    "        \n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.relu(self.gc6(x, adj))\n",
    "        x = F.sigmoid(self.out(x))\n",
    "        #return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    '''\n",
    "    \n",
    "    This code is copied from openAI baselines\n",
    "    https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
    "    '''\n",
    "    def __init__(self, size):\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        \n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes , dtype = np.float32):\n",
    "        \n",
    "        \n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False,dtype=dtype))\n",
    "            actions.append(np.array(action, copy=False,dtype=np.long))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False,dtype=dtype))\n",
    "            dones.append(done)\n",
    "        return np.array(obses_t,dtype=dtype), np.array(actions , dtype = np.long), \\\n",
    "    np.array(rewards  ,dtype=dtype), np.array(obses_tp1,dtype=dtype), np.array(dones , dtype = bool)\n",
    "    \n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)\n",
    "\n",
    "    \n",
    "class Agent():\n",
    "    \n",
    "    def __init__(self , num_state , num_action):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.policy_network = network(num_state , num_action)\n",
    "        self.target_network = network(num_state , num_action)\n",
    "        \n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "        \n",
    "        self.steps_done = 0\n",
    "        self.num_state = num_state\n",
    "        self.num_action = num_action\n",
    "        \n",
    "        self.EPS_END = 0.05\n",
    "        self.EPS_START = 0.999\n",
    "    \n",
    "        self.EPS_DECAY = 3000\n",
    "        self.batch_size = 64\n",
    "        self.buffer = ReplayBuffer( 4000 )\n",
    "#         self.optimizer = torch.optim.Adam(self.policy_network.parameters()   ,lr=0.0001, amsgrad=True)\n",
    "        self.optimizer = torch.optim.AdamW(self.policy_network.parameters(),lr=0.000005)\n",
    "    def take_action(self , x , mask ,is_testing = False ) :\n",
    "        eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * \\\n",
    "            math.exp(-1. * self.steps_done / self.EPS_DECAY)\n",
    "#         for i in range(len(x)):\n",
    "#             x[i] = x[i].astype(np.float32)\n",
    "#             x[i] = torch.from_numpy(x[i])\n",
    "        x = torch.FloatTensor(x)\n",
    "        rand_val = np.random.uniform()\n",
    "        if rand_val > eps_threshold or is_testing == True:\n",
    "            val = self.policy_network(x,Adj)\n",
    "            for i in range(len(val)):\n",
    "                if(i not in mask):\n",
    "                    val[i] = float('-Infinity')\n",
    "            action = torch.argmax(val).item()\n",
    "            \n",
    "        else:\n",
    "            action = int(np.random.choice(mask))\n",
    "        \n",
    "        if is_testing == False:\n",
    "            self.steps_done += 1\n",
    "        \n",
    "        return action\n",
    "            \n",
    "    \n",
    "    def store_transition(self, state , action , reward , next_state , done):\n",
    "        \n",
    "        self.buffer.add(state , action , reward , next_state , done)\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return \n",
    "        loss_fn = torch.nn.MSELoss(reduction = 'mean')\n",
    "        \n",
    "        batch = self.buffer.sample(self.batch_size)\n",
    "        states , actions , rewards , next_states , dones = batch\n",
    "        states = torch.from_numpy(states)\n",
    "        actions = torch.from_numpy(actions).view(-1,1)\n",
    "        rewards = torch.from_numpy(rewards)\n",
    "        next_states = torch.from_numpy(next_states)\n",
    "        actions = actions.long()\n",
    "        \n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s : s != True, dones)),dtype = torch.bool)\n",
    "        non_final_next_state = next_states[non_final_mask]\n",
    "        \n",
    "#         print(self.policy_network(states[0],Adj).view(-1))\n",
    "        #print(self.policy_network(states[0],Adj)[0].gather(0 , actions[0]).shape)\n",
    "        pred_q = torch.zeros(self.batch_size).detach()\n",
    "        for i in range(self.batch_size):\n",
    "            pred_q[i] = self.policy_network(states[i],Adj).view(-1).gather(0 , actions[i]).view(-1)\n",
    "            \n",
    "        \n",
    "        next_state_value = torch.zeros(self.batch_size).detach()\n",
    "        for i in range(len(non_final_next_state)):\n",
    "            D_action = self.policy_network(non_final_next_state[i],Adj).view(-1).argmax(0)\n",
    "            next_state_value[i] = self.target_network(non_final_next_state[i],Adj).view(-1).gather(0 , D_action).view(-1)\n",
    "            \n",
    "        expected_q = (next_state_value + rewards).detach()\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(pred_q , expected_q)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def update_target_weight(self):\n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(nodes, node1, node2):\n",
    "    x = (nodes[node1][1] - nodes[node2][1])**2\n",
    "    y = (nodes[node1][2] - nodes[node2][2])**2\n",
    "    return (x+y)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering():\n",
    "    check_list = []\n",
    "    count = -1\n",
    "    clustering_info = []\n",
    "    for index in range(num_nodes):\n",
    "        prev_check_list = []\n",
    "        if index not in check_list:\n",
    "            count+=1\n",
    "            clustering_info.append([])\n",
    "            check_list.append(index)\n",
    "            prev_check_list.append(index)\n",
    "            clustering_info[count].append(index)\n",
    "            while(len(prev_check_list)!=0):\n",
    "                next_check_list = []\n",
    "                for j in range (len(prev_check_list)):\n",
    "                    node1 = prev_check_list[j]\n",
    "                    i = 0\n",
    "                    while(i<len(nodes_dis[node1]) and nodes_dis[node1][i][1]<=t_constraint):\n",
    "                        node2 = nodes_dis[node1][i][0]\n",
    "                        if node2 not in check_list:\n",
    "                            check_list.append(node2)\n",
    "                            next_check_list.append(node2)\n",
    "                            clustering_info[count].append(node2)\n",
    "                        i+=1    \n",
    "                prev_check_list = next_check_list\n",
    "    return clustering_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communication():\n",
    "    for i in range(k_agents): \n",
    "        for j in range(i+1,k_agents):\n",
    "            if nodes_dis2[now_point[i]][now_point[j]] < t_constraint:\n",
    "                for k in range(num_nodes):\n",
    "                    for z in range(k+1, num_nodes):\n",
    "                        s = max(state_map[i][k][z],state_map[j][k][z])\n",
    "                        state_map[i][k][z] = s\n",
    "                        state_map[j][k][z] = s\n",
    "                        state_map[i][z][k] = s\n",
    "                        state_map[j][z][k] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    data = open(\"data2.txt\",'w+') \n",
    "    num_nodes = 5\n",
    "    print(num_nodes, file=data)\n",
    "    num_edges = random.randint((num_nodes-1)*(num_nodes-2)/2+1,num_nodes*(num_nodes-1)/2)\n",
    "    print(num_edges, file=data)\n",
    "    random_list = [0] * num_nodes\n",
    "    state_check = []\n",
    "    for i in range(num_nodes):\n",
    "        state_check.append([])\n",
    "        random_list[i] = i\n",
    "        pos_x = random.randint(0,1000)\n",
    "        pos_y = random.randint(0,1000)\n",
    "        print(i, pos_x, pos_y, file=data)\n",
    "    for i in range(num_edges):\n",
    "        flag_input = 0\n",
    "        while flag_input == 0: \n",
    "            sample_list = random.sample(random_list,2)\n",
    "            length = random.randint(0,1000)\n",
    "            a = sample_list[0]\n",
    "            b = sample_list[1]\n",
    "            if b not in state_check[a]:\n",
    "                state_check[a].append(b)\n",
    "                state_check[b].append(a)\n",
    "                print(a, b, length, file=data)\n",
    "                flag_input = 1\n",
    "            else:\n",
    "                flag_input = 0\n",
    "    k_agents = 3\n",
    "    print(k_agents, file=data)\n",
    "    for i in range(k_agents):\n",
    "        now_point = random.randint(0,num_nodes-1)\n",
    "        speed = random.randint(1,10)\n",
    "        print(i, now_point, speed, file=data)\n",
    "    constraint = 500\n",
    "    print(constraint, file=data)\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063944457add43bba4fe4b62c2d99b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "[0, 1, 0]\n",
      "-11.741999999999997\n",
      "2702\n",
      "[0, 4, 2]\n",
      "3.7970000000000006\n",
      "1635\n",
      "[5, 2, 4]\n",
      "-17.055\n",
      "3052\n",
      "[6, 4, 3]\n",
      "36.821999999999996\n",
      "1443\n",
      "[3, 0, 3]\n",
      "-2.094000000000003\n",
      "2009\n",
      "[6, 0, 4]\n",
      "-23.37699999999999\n",
      "3524\n",
      "[4, 2, 3]\n",
      "-19.629000000000005\n",
      "3246\n",
      "[5, 3, 0]\n",
      "-48.90999999999992\n",
      "5127\n",
      "[3, 2, 1]\n",
      "-0.29600000000000115\n",
      "1954\n",
      "[0, 1, 5]\n",
      "-25.060999999999986\n",
      "3579\n",
      "[0, 5, 2]\n",
      "-5.153999999999998\n",
      "2247\n",
      "[5, 1, 2]\n",
      "-7.806999999999999\n",
      "2478\n",
      "[6, 1, 5]\n",
      "-7.89200000000001\n",
      "2484\n",
      "[2, 3, 3]\n",
      "-14.129999999999999\n",
      "2901\n",
      "[5, 1, 4]\n",
      "-40.62299999999999\n",
      "4642\n",
      "[0, 1, 0]\n",
      "-18.607999999999983\n",
      "3176\n",
      "[0, 2, 5]\n",
      "-30.42699999999998\n",
      "4014\n",
      "[5, 6, 3]\n",
      "-56.34699999999993\n",
      "5688\n",
      "[3, 6, 5]\n",
      "-7.917999999999996\n",
      "2417\n",
      "[4, 3, 3]\n",
      "-25.89199999999999\n",
      "3700\n",
      "[3, 6, 0]\n",
      "-31.87199999999997\n",
      "4041\n",
      "[5, 6, 6]\n",
      "-22.26299999999996\n",
      "3412\n",
      "[0, 3, 3]\n",
      "-54.28399999999995\n",
      "5580\n",
      "[3, 2, 0]\n",
      "-0.2140000000000022\n",
      "1900\n",
      "[6, 2, 5]\n",
      "-82.92999999999995\n",
      "7474\n",
      "[4, 1, 0]\n",
      "-45.91499999999995\n",
      "4973\n",
      "[2, 0, 6]\n",
      "-35.41999999999995\n",
      "4319\n",
      "[3, 6, 5]\n",
      "-47.614999999999895\n",
      "5109\n",
      "[0, 0, 4]\n",
      "-227.76500000000118\n",
      "17156\n",
      "[4, 4, 6]\n",
      "-21.992999999999977\n",
      "3420\n",
      "[6, 4, 5]\n",
      "-207.13800000000094\n",
      "15741\n",
      "[3, 2, 5]\n",
      "-359.3769999999998\n",
      "25891\n",
      "[2, 6, 0]\n",
      "-295.2699999999996\n",
      "21615\n",
      "[0, 4, 5]\n",
      "-3306.6580000018203\n",
      "222354\n",
      "[5, 3, 2]\n",
      "-589.3240000000031\n",
      "41275\n",
      "[0, 3, 2]\n",
      "-2259.288999999781\n",
      "152531\n",
      "[1, 0, 0]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-38206c414814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-19209e1362ee>\u001b[0m in \u001b[0;36mupdate_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_final_next_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mD_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_final_next_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mnext_state_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_final_next_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mD_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mexpected_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_state_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-19209e1362ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file=open('data_7.txt')\n",
    "lines = file.readlines()\n",
    "num_nodes = int(lines[0])\n",
    "num_edges = int(lines[1])\n",
    "agent = Agent(num_nodes , num_nodes)\n",
    "reward_history = []\n",
    "cost = 3000\n",
    "for e in tqdm(range(200)):\n",
    "    print(cost)\n",
    "    nodes = []\n",
    "    state = []\n",
    "    edge_len = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    god_map = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    nodes_dis = []\n",
    "    nodes_dis2 = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    on_nodes = []\n",
    "    info_speed = []\n",
    "    features = []\n",
    "    prev_features = []\n",
    "    features = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    prev_features = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    Adj = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    for i in range(num_nodes):\n",
    "        state.append([])\n",
    "        nodes_dis.append([])\n",
    "        on_nodes.append([])\n",
    "        curLine = lines[i+2].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        nodes.append([intLine[0], intLine[1], intLine[2]])\n",
    "        for j in range(i-1, -1, -1):\n",
    "            dis = distance(nodes, i, j)\n",
    "            nodes_dis[i].append((j, dis))\n",
    "            nodes_dis[j].append((i, dis))\n",
    "            nodes_dis2[i][j] = dis\n",
    "            nodes_dis2[j][i] = dis\n",
    "    for i in range(len(nodes_dis)):\n",
    "        nodes_dis[i].sort(key=lambda nodes_dis: nodes_dis[1])\n",
    "\n",
    "    for i in range(num_edges):\n",
    "        curLine = lines[i+2+num_nodes].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        state[intLine[0]].append(intLine[1])\n",
    "        state[intLine[1]].append(intLine[0])\n",
    "        edge_len[intLine[0]][intLine[1]] = intLine[2]\n",
    "        edge_len[intLine[1]][intLine[0]] = intLine[2]\n",
    "        Adj[intLine[0]][intLine[1]] = 1\n",
    "        Adj[intLine[1]][intLine[0]] = 1\n",
    "#     for i in range(num_nodes):\n",
    "#         for j in range(num_nodes):\n",
    "#             features[i][j] = edge_len[i][j]\n",
    "#             prev_features[i][j] = edge_len[i][j]\n",
    "    Adj = torch.FloatTensor(Adj)\n",
    "    k_agents = int(lines[2+num_nodes+num_edges])\n",
    "\n",
    "    now_point = [0] * k_agents\n",
    "    speed = [0]*k_agents\n",
    "    target = [0]*k_agents\n",
    "    location = [0]*k_agents\n",
    "    x_agent = []\n",
    "    y_agent = []\n",
    "\n",
    "    for i in range(k_agents):\n",
    "        x_agent.append([])\n",
    "        y_agent.append([])\n",
    "        info_speed.append([])\n",
    "        curLine = lines[i+3+num_nodes+num_edges].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        #now_point[intLine[0]] = intLine[1]\n",
    "        now_point[i] = random.randint(0, num_nodes-1)\n",
    "        speed[intLine[0]] = intLine[2]\n",
    "\n",
    "    t_constraint = int(lines[3+num_nodes+num_edges+k_agents])\n",
    "\n",
    "    print(now_point)\n",
    "    \n",
    "    history_route = []\n",
    "    state_map = []\n",
    "    for i in range(k_agents):\n",
    "        history_route.append([])\n",
    "        history_route[i].append(now_point[i])\n",
    "        on_nodes[now_point[i]].append(i)\n",
    "        state_map.append([]) \n",
    "    for i in range(k_agents):\n",
    "        state_map[i] = [[0] * num_nodes for i in range(num_nodes)]\n",
    "    \n",
    "    finish_count = 0\n",
    "    cost = 0\n",
    "    pre_step = [0]*k_agents\n",
    "    info_clustering = clustering()\n",
    "    reward_sum = 0.0\n",
    "    while finish_count < num_edges:\n",
    "        #communication()\n",
    "        cost+=1\n",
    "        for i in range(k_agents):\n",
    "            list_x = []\n",
    "            list_y = []\n",
    "            if target[i]==0:\n",
    "                \n",
    "                for state_index in range(num_nodes):\n",
    "                    for state_index2 in range(num_nodes):\n",
    "                        if(god_map[state_index][state_index2] >= 1):\n",
    "                            features[state_index][state_index2] = 1\n",
    "                reward = 0\n",
    "                pre_step[i] = now_point[i]\n",
    "                action = agent.take_action(np.array(features), state[now_point[i]])\n",
    "                for index_i in range(len(features)):\n",
    "                    for index_j in range(len(features[index_i])):\n",
    "                        prev_features[index_i][index_j] = features[index_i][index_j]\n",
    "                now_point[i] = action\n",
    "                \n",
    "                if(god_map[pre_step[i]][now_point[i]] == 0):\n",
    "                    reward += 1\n",
    "#                 else:\n",
    "#                     reward -= features[pre_step[i]][now_point[i]] * 0.001\n",
    "                reward -= edge_len[pre_step[i]][now_point[i]] * 0.001\n",
    "                if(finish_count >= num_edges - 1 and god_map[now_point[i]][pre_step[i]]==0):\n",
    "                    done = True\n",
    "                    reward += 10\n",
    "                    if(cost <= 1500):\n",
    "                        reward += 30\n",
    "                else:\n",
    "                    done = False\n",
    "                    \n",
    "                reward_sum += reward \n",
    "                \n",
    "                if god_map[now_point[i]][pre_step[i]]==0:\n",
    "                    finish_count+=1\n",
    "                god_map[now_point[i]][pre_step[i]] += 1\n",
    "                god_map[pre_step[i]][now_point[i]] += 1\n",
    "                features[pre_step[i]][now_point[i]] = 1\n",
    "                features[now_point[i]][pre_step[i]] = 1\n",
    "                    \n",
    "                agent.store_transition(np.array(prev_features) , action , reward , np.array(features), done)\n",
    "                agent.update_parameters()\n",
    "                \n",
    "                target[i] = edge_len[now_point[i]][pre_step[i]]/speed[i]\n",
    "            location[i]+=1\n",
    "            draw_flag = 0\n",
    "            while location[i]>=target[i]:\n",
    "#                 state_map[i][now_point[i]][pre_step[i]] += 1\n",
    "#                 state_map[i][pre_step[i]][now_point[i]] += 1\n",
    "                history_route[i].append(now_point[i])\n",
    "#                 if god_map[now_point[i]][pre_step[i]]==0:\n",
    "#                     finish_count+=1\n",
    "#                     god_map[now_point[i]][pre_step[i]] += 1\n",
    "#                     god_map[pre_step[i]][now_point[i]] += 1\n",
    "\n",
    "                if(draw_flag == 0):\n",
    "                    pre_x = ((location[i]-1)/target[i])*nodes[now_point[i]][1] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][1]\n",
    "                    pre_y = ((location[i]-1)/target[i])*nodes[now_point[i]][2] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][2]\n",
    "                    now_x = nodes[now_point[i]][1] \n",
    "                    now_y = nodes[now_point[i]][2] \n",
    "                    list_x.append([pre_x, now_x])\n",
    "                    list_y.append([pre_y, now_y])\n",
    "                else:\n",
    "                    pre_x = nodes[pre_step[i]][1]\n",
    "                    pre_y = nodes[pre_step[i]][2] \n",
    "                    now_x = nodes[now_point[i]][1] \n",
    "                    now_y = nodes[now_point[i]][2] \n",
    "                    list_x.append([pre_x, now_x])\n",
    "                    list_y.append([pre_y, now_y])\n",
    "                    \n",
    "                for state_index in range(num_nodes):\n",
    "                    for state_index2 in range(num_nodes):\n",
    "                        if(god_map[state_index][state_index2] >= 1):\n",
    "                            features[state_index][state_index2] = 1\n",
    "                reward = 0\n",
    "                pre_step[i] = now_point[i]\n",
    "                action = agent.take_action(np.array(features), state[now_point[i]])\n",
    "                for index_i in range(len(features)):\n",
    "                    for index_j in range(len(features[index_i])):\n",
    "                        prev_features[index_i][index_j] = features[index_i][index_j]\n",
    "                now_point[i] = action\n",
    "    \n",
    "                \n",
    "                if(god_map[pre_step[i]][now_point[i]] == 0):\n",
    "                    reward += 1\n",
    "#                 else:\n",
    "#                     reward -= features[pre_step[i]][now_point[i]] * 0.001\n",
    "                reward -= edge_len[pre_step[i]][now_point[i]] * 0.001\n",
    "                if(finish_count >= num_edges - 1 and god_map[now_point[i]][pre_step[i]]==0):\n",
    "                    done = True\n",
    "                    reward += 10\n",
    "                    if(cost <= 1500):\n",
    "                        reward += 30\n",
    "                else:\n",
    "                    done = False\n",
    "                    \n",
    "                reward_sum += reward \n",
    "                \n",
    "                if god_map[now_point[i]][pre_step[i]]==0:\n",
    "                    finish_count+=1\n",
    "                god_map[now_point[i]][pre_step[i]] += 1\n",
    "                god_map[pre_step[i]][now_point[i]] += 1\n",
    "                features[pre_step[i]][now_point[i]] = 1\n",
    "                features[now_point[i]][pre_step[i]] = 1\n",
    "                    \n",
    "                agent.store_transition(np.array(prev_features) , action , reward , np.array(features), done)\n",
    "                agent.update_parameters()\n",
    "                \n",
    "                location[i] = location[i]-target[i]\n",
    "                target[i] = edge_len[now_point[i]][pre_step[i]]/speed[i]\n",
    "                if i in on_nodes[pre_step[i]]:\n",
    "                    on_nodes[pre_step[i]].remove(i)\n",
    "                draw_flag = 1\n",
    "            if (draw_flag == 1):\n",
    "                pre_x = nodes[pre_step[i]][1] \n",
    "                pre_y = nodes[pre_step[i]][2]\n",
    "                now_x = ((location[i])/target[i])*nodes[now_point[i]][1] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][1]\n",
    "                now_y = ((location[i])/target[i])*nodes[now_point[i]][2] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][2]\n",
    "                list_x.append([pre_x, now_x])\n",
    "                list_y.append([pre_y, now_y])\n",
    "                x_agent[i].append(list_x)\n",
    "                y_agent[i].append(list_y)\n",
    "            else:\n",
    "                pre_x = ((location[i]-1)/target[i])*nodes[now_point[i]][1] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][1]\n",
    "                pre_y = ((location[i]-1)/target[i])*nodes[now_point[i]][2] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][2]\n",
    "                now_x = ((location[i])/target[i])*nodes[now_point[i]][1] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][1]\n",
    "                now_y = ((location[i])/target[i])*nodes[now_point[i]][2] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][2]\n",
    "                x_agent[i].append([pre_x, now_x])\n",
    "                y_agent[i].append([pre_y, now_y])\n",
    "\n",
    "            if (location[i]/target[i]) > 0.5:\n",
    "                if i not in on_nodes[now_point[i]]:\n",
    "                    on_nodes[now_point[i]].append(i)\n",
    "            else:\n",
    "                if i not in on_nodes[pre_step[i]]:\n",
    "                    on_nodes[pre_step[i]].append(i)\n",
    "    reward_history.append(reward_sum)\n",
    "    if e  % 1 == 0:\n",
    "        print(reward_sum)\n",
    "    if e > 0 and e % 30 == 0:\n",
    "        agent.update_target_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  1996 ticks\n"
     ]
    }
   ],
   "source": [
    "print('cost: ', cost, 'ticks')\n",
    "#print(history_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23e0111e10>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "x = []\n",
    "y = []\n",
    "for i in range(num_nodes):\n",
    "    node1 = i\n",
    "    for node2 in state[i]:\n",
    "        x.append([nodes[node1][1], nodes[node2][1]])\n",
    "        y.append([nodes[node1][2], nodes[node2][2]])\n",
    "\n",
    "x_1data = []\n",
    "y_1data = []\n",
    "x_2data = []\n",
    "y_2data = []\n",
    "x_3data = []\n",
    "y_3data = []\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 1000)\n",
    "ax.set_ylim(0, 1000)\n",
    "line, = ax.plot(0, 0, color = 'silver')\n",
    "line_1, = ax.plot(0, 0, color='red')\n",
    "line_2, = ax.plot(0, 0, color='black')\n",
    "line_3, = ax.plot(0, 0, color='blue')\n",
    "ball_1 = plt.Circle((5, -5), 18, fc='red')\n",
    "ball_2 = plt.Circle((5, -5), 18, fc='black')\n",
    "ball_3 = plt.Circle((5, -5), 18, fc='blue')\n",
    "def animation_frame(i):\n",
    "    \n",
    "    if i >= 0:\n",
    "        if(i<len(x_agent[0])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[0][i])):\n",
    "                if isinstance(x_agent[0][i][j], list):\n",
    "                    x_1data.append(x_agent[0][i][j])\n",
    "                    y_1data.append(y_agent[0][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_1.center = (x_agent[0][i][j][1], y_agent[0][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_1data.append(x_agent[0][i])\n",
    "                y_1data.append(y_agent[0][i])\n",
    "                ball_1.center = (x_agent[0][i][1], y_agent[0][i][1])\n",
    "\n",
    "            line_1.set_xdata(x_1data)\n",
    "            line_1.set_ydata(y_1data)\n",
    "            \n",
    "            \n",
    "\n",
    "        if(i<len(x_agent[1])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[1][i])):\n",
    "                if isinstance(x_agent[1][i][j], list):\n",
    "                    x_2data.append(x_agent[1][i][j])\n",
    "                    y_2data.append(y_agent[1][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_2.center = (x_agent[1][i][j][1], y_agent[1][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_2data.append(x_agent[1][i])\n",
    "                y_2data.append(y_agent[1][i])\n",
    "                ball_2.center = (x_agent[1][i][1], y_agent[1][i][1])\n",
    "                \n",
    "            line_2.set_xdata(x_2data)\n",
    "            line_2.set_ydata(y_2data)\n",
    "            \n",
    "        if(i<len(x_agent[2])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[2][i])):\n",
    "                if isinstance(x_agent[2][i][j], list):\n",
    "                    x_3data.append(x_agent[2][i][j])\n",
    "                    y_3data.append(y_agent[2][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_3.center = (x_agent[2][i][j][1], y_agent[2][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_3data.append(x_agent[2][i])\n",
    "                y_3data.append(y_agent[2][i])\n",
    "                ball_3.center = (x_agent[2][i][1], y_agent[2][i][1])\n",
    "\n",
    "            line_3.set_xdata(x_3data)\n",
    "            line_3.set_ydata(y_3data)\n",
    "    \n",
    "    return line_1,line_2,line_3,ball_1,ball_2,ball_3,\n",
    "def init():\n",
    "    line.set_xdata(x)\n",
    "    line.set_ydata(y)\n",
    "    \n",
    "    line_1.set_xdata(x_agent[0][0][0])\n",
    "    line_1.set_ydata(y_agent[0][0][0])\n",
    "    \n",
    "    line_2.set_xdata(x_agent[1][0][0])\n",
    "    line_2.set_ydata(y_agent[1][0][0])\n",
    "    \n",
    "    line_3.set_xdata(x_agent[2][0][0])\n",
    "    line_3.set_ydata(y_agent[2][0][0])\n",
    "    \n",
    "    ball_1.center = (x_agent[0][0][0], y_agent[0][0][0])\n",
    "    ax.add_patch(ball_1)\n",
    "    \n",
    "    ball_2.center = (x_agent[1][0][0], y_agent[1][0][0])\n",
    "    ax.add_patch(ball_2)\n",
    "    \n",
    "    ball_3.center = (x_agent[2][0][0], y_agent[2][0][0])\n",
    "    ax.add_patch(ball_3)\n",
    "    \n",
    "    return line, line_1,line_2,line_3, ball_1,ball_2,ball_3,\n",
    "    \n",
    "animation = FuncAnimation(fig, func=animation_frame, frames=np.arange(-2, len(x_agent[0]), 1), init_func=init, interval=10)\n",
    "plt.show()\n",
    "animation.save('basic_animation2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 398 396\n"
     ]
    }
   ],
   "source": [
    "print(len(x_1data),len(x_2data),len(x_3data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 3, 1], [3, 0, 2, 4], [3, 4, 1], [0, 1, 2, 4], [0, 2, 3, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2020-08-03T14:20 31 30 31 30 5\n",
    "    2020-12-09T11:30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
