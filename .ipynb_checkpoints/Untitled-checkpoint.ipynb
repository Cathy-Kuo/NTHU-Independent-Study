{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    \n",
    "    def __init__(self , num_state , num_action):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.gc1 = GraphConvolution(num_state, 64)\n",
    "        self.gc2 = GraphConvolution(64, num_action)\n",
    "        self.out = nn.Linear(num_action , num_action)\n",
    "        #self.dropout = dropout\n",
    "        \n",
    "    def forward(self , x, adj):\n",
    "        \n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        #x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc2(x, adj))\n",
    "        x = self.out(x)\n",
    "        #return F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    '''\n",
    "    \n",
    "    This code is copied from openAI baselines\n",
    "    https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
    "    '''\n",
    "    def __init__(self, size):\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        \n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes , dtype = np.float32):\n",
    "        \n",
    "        \n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False,dtype=dtype))\n",
    "            actions.append(np.array(action, copy=False,dtype=np.long))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False,dtype=dtype))\n",
    "            dones.append(done)\n",
    "        return np.array(obses_t,dtype=dtype), np.array(actions , dtype = np.long), \\\n",
    "    np.array(rewards  ,dtype=dtype), np.array(obses_tp1,dtype=dtype), np.array(dones , dtype = bool)\n",
    "    \n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)\n",
    "\n",
    "    \n",
    "class Agent():\n",
    "    \n",
    "    def __init__(self , num_state , num_action):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.policy_network = network(num_state , num_action)\n",
    "        self.target_network = network(num_state , num_action)\n",
    "        \n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "        \n",
    "        self.steps_done = 0\n",
    "        self.num_state = num_state\n",
    "        self.num_action = num_action\n",
    "        \n",
    "        self.EPS_END = 0.05\n",
    "        self.EPS_START = 0.999\n",
    "        \n",
    "        self.EPS_DECAY = 1000\n",
    "        self.batch_size = 64\n",
    "        self.buffer = ReplayBuffer( 4000 )\n",
    "        self.optimizer = torch.optim.Adam(self.policy_network.parameters()   , amsgrad=True)\n",
    "        \n",
    "    def take_action(self , x , mask ,is_testing = False ) :\n",
    "        eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * \\\n",
    "            math.exp(-1. * self.steps_done / self.EPS_DECAY)\n",
    "#         for i in range(len(x)):\n",
    "#             x[i] = x[i].astype(np.float32)\n",
    "#             x[i] = torch.from_numpy(x[i])\n",
    "        x = torch.FloatTensor(x)\n",
    "        rand_val = np.random.uniform()\n",
    "        if rand_val > eps_threshold or is_testing == True:\n",
    "            val = self.policy_network(x,Adj)[0]\n",
    "            action = torch.argmax(val).item()\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            action = int(np.random.choice(mask))\n",
    "        \n",
    "        if is_testing == False:\n",
    "            self.steps_done += 1\n",
    "        \n",
    "        return action\n",
    "            \n",
    "    \n",
    "    def store_transition(self, state , action , reward , next_state , done):\n",
    "        \n",
    "        self.buffer.add(state , action , reward , next_state , done)\n",
    "    \n",
    "    def update_parameters(self):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return \n",
    "        loss_fn = torch.nn.MSELoss(reduction = 'mean')\n",
    "        \n",
    "        batch = self.buffer.sample(self.batch_size)\n",
    "        states , actions , rewards , next_states , dones = batch\n",
    "        states = torch.from_numpy(states)\n",
    "        actions = torch.from_numpy(actions).view(-1,1)\n",
    "        rewards = torch.from_numpy(rewards)\n",
    "        next_states = torch.from_numpy(next_states)\n",
    "        actions = actions.long()\n",
    "        \n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s : s != True, dones)),dtype = torch.bool)\n",
    "        non_final_next_state = next_states[non_final_mask]\n",
    "        \n",
    "        pred_q = self.policy_network(states,Adj).gather(1 , actions).view(-1) \n",
    "        \n",
    "        next_state_value = torch.zeros(self.batch_size).detach()\n",
    "        next_state_value[non_final_mask] = self.target_network(non_final_next_state).max(1)[0]\n",
    "        expected_q = (next_state_value + rewards).detach()\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(pred_q , expected_q)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def update_target_weight(self):\n",
    "        self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(nodes, node1, node2):\n",
    "    x = (nodes[node1][1] - nodes[node2][1])**2\n",
    "    y = (nodes[node1][2] - nodes[node2][2])**2\n",
    "    return (x+y)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering():\n",
    "    check_list = []\n",
    "    count = -1\n",
    "    clustering_info = []\n",
    "    for index in range(num_nodes):\n",
    "        prev_check_list = []\n",
    "        if index not in check_list:\n",
    "            count+=1\n",
    "            clustering_info.append([])\n",
    "            check_list.append(index)\n",
    "            prev_check_list.append(index)\n",
    "            clustering_info[count].append(index)\n",
    "            while(len(prev_check_list)!=0):\n",
    "                next_check_list = []\n",
    "                for j in range (len(prev_check_list)):\n",
    "                    node1 = prev_check_list[j]\n",
    "                    i = 0\n",
    "                    while(i<len(nodes_dis[node1]) and nodes_dis[node1][i][1]<=t_constraint):\n",
    "                        node2 = nodes_dis[node1][i][0]\n",
    "                        if node2 not in check_list:\n",
    "                            check_list.append(node2)\n",
    "                            next_check_list.append(node2)\n",
    "                            clustering_info[count].append(node2)\n",
    "                        i+=1    \n",
    "                prev_check_list = next_check_list\n",
    "    return clustering_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communication():\n",
    "    for i in range(len(info_clustering)):\n",
    "        communication_list = []\n",
    "        for node1 in info_clustering[i]:\n",
    "            for agent in on_nodes[node1]:\n",
    "                communication_list.append(agent)\n",
    "        for index_1 in range(len(communication_list)-1):\n",
    "            for index_2 in range(index_1+1, len(communication_list)):\n",
    "                agent_1 = communication_list[index_1]\n",
    "                agent_2 = communication_list[index_2]\n",
    "                if agent_1 not in info_speed[agent_2]:\n",
    "                    info_speed[agent_1].append(agent_2)\n",
    "                    info_speed[agent_2].append(agent_1)\n",
    "                for agent in info_speed[agent_1]:\n",
    "                    if agent not in info_speed[agent_2]:\n",
    "                        info_speed[agent_2].append(agent)\n",
    "                for agent in info_speed[agent_2]:\n",
    "                    if agent not in info_speed[agent_1]:\n",
    "                        info_speed[agent_1].append(agent)\n",
    "                for j in range(num_nodes):\n",
    "                    for k in range(num_nodes):\n",
    "                        if(state_map[agent_1][j][k] == 1 or state_map[agent_2][j][k] == 1):\n",
    "                            state_map[agent_1][j][k] = 1\n",
    "                            state_map[agent_2][j][k] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    data = open(\"data2.txt\",'w+') \n",
    "    num_nodes = 5\n",
    "    print(num_nodes, file=data)\n",
    "    num_edges = random.randint((num_nodes-1)*(num_nodes-2)/2+1,num_nodes*(num_nodes-1)/2)\n",
    "    print(num_edges, file=data)\n",
    "    random_list = [0] * num_nodes\n",
    "    state_check = []\n",
    "    for i in range(num_nodes):\n",
    "        state_check.append([])\n",
    "        random_list[i] = i\n",
    "        pos_x = random.randint(0,1000)\n",
    "        pos_y = random.randint(0,1000)\n",
    "        print(i, pos_x, pos_y, file=data)\n",
    "    for i in range(num_edges):\n",
    "        flag_input = 0\n",
    "        while flag_input == 0: \n",
    "            sample_list = random.sample(random_list,2)\n",
    "            length = random.randint(0,1000)\n",
    "            a = sample_list[0]\n",
    "            b = sample_list[1]\n",
    "            if b not in state_check[a]:\n",
    "                state_check[a].append(b)\n",
    "                state_check[b].append(a)\n",
    "                print(a, b, length, file=data)\n",
    "                flag_input = 1\n",
    "            else:\n",
    "                flag_input = 0\n",
    "    k_agents = 3\n",
    "    print(k_agents, file=data)\n",
    "    for i in range(k_agents):\n",
    "        now_point = random.randint(0,num_nodes-1)\n",
    "        speed = random.randint(1,10)\n",
    "        print(i, now_point, speed, file=data)\n",
    "    constraint = 500\n",
    "    print(constraint, file=data)\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90b5a5e34d74388bbf0f0601dc592b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n",
      "-24.18\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 3D, 2D tensors at /Users/distiller/project/conda/conda-bld/pytorch_1579022061893/work/aten/src/TH/generic/THTensorMath.cpp:131",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a9a1df0de2d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mreward_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-74e81b9161d5>\u001b[0m in \u001b[0;36mupdate_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mnon_final_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mnon_final_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_final_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mpred_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAdj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-74e81b9161d5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m#x = F.dropout(x, self.dropout, training=self.training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-57706b357507>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, adj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msupport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: matrices expected, got 3D, 2D tensors at /Users/distiller/project/conda/conda-bld/pytorch_1579022061893/work/aten/src/TH/generic/THTensorMath.cpp:131"
     ]
    }
   ],
   "source": [
    "file=open('data2.txt')\n",
    "lines = file.readlines()\n",
    "num_nodes = int(lines[0])\n",
    "num_edges = int(lines[1])\n",
    "agent = Agent(1 , num_nodes)\n",
    "reward_history = []\n",
    "for e in tqdm(range(1000)):\n",
    "    nodes = []\n",
    "    state = []\n",
    "    edge_len = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    god_map = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    nodes_dis = []\n",
    "    on_nodes = []\n",
    "    info_speed = []\n",
    "    features = []\n",
    "    prev_features = []\n",
    "    Adj = [[0]*num_nodes for i in range(num_nodes)]\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        features.append([0])\n",
    "        prev_features.append([0])\n",
    "        state.append([])\n",
    "        nodes_dis.append([])\n",
    "        on_nodes.append([])\n",
    "        curLine = lines[i+2].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        nodes.append([intLine[0], intLine[1], intLine[2]])\n",
    "        for j in range(i-1, -1, -1):\n",
    "            dis = distance(nodes, i, j)\n",
    "            nodes_dis[i].append((j, dis))\n",
    "            nodes_dis[j].append((i, dis))\n",
    "    for i in range(len(nodes_dis)):\n",
    "        nodes_dis[i].sort(key=lambda nodes_dis: nodes_dis[1])\n",
    "\n",
    "    for i in range(num_edges):\n",
    "        curLine = lines[i+2+num_nodes].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        state[intLine[0]].append(intLine[1])\n",
    "        state[intLine[1]].append(intLine[0])\n",
    "        edge_len[intLine[0]][intLine[1]] = intLine[2]\n",
    "        edge_len[intLine[1]][intLine[0]] = intLine[2]\n",
    "        Adj[intLine[0]][intLine[1]] = 1\n",
    "        Adj[intLine[1]][intLine[0]] = 1\n",
    "    Adj = torch.FloatTensor(Adj)\n",
    "    k_agents = int(lines[2+num_nodes+num_edges])\n",
    "\n",
    "    now_point = [0] * k_agents\n",
    "    speed = [0]*k_agents\n",
    "    target = [0]*k_agents\n",
    "    location = [0]*k_agents\n",
    "    x_agent = []\n",
    "    y_agent = []\n",
    "\n",
    "    for i in range(k_agents):\n",
    "        x_agent.append([])\n",
    "        y_agent.append([])\n",
    "        info_speed.append([])\n",
    "        curLine = lines[i+3+num_nodes+num_edges].strip().split(\" \")\n",
    "        intLine = list(map(int, curLine))\n",
    "        now_point[intLine[0]] = intLine[1]\n",
    "        speed[intLine[0]] = intLine[2]\n",
    "\n",
    "    t_constraint = int(lines[3+num_nodes+num_edges+k_agents])\n",
    "\n",
    "#     print(now_point)\n",
    "#     print(state)\n",
    "#     print(speed)\n",
    "#     print(edge_len)\n",
    "    \n",
    "    history_route = []\n",
    "    state_map = []\n",
    "    for i in range(k_agents):\n",
    "        history_route.append([])\n",
    "        history_route[i].append(now_point[i])\n",
    "        on_nodes[now_point[i]].append(i)\n",
    "        state_map.append([]) \n",
    "    for i in range(k_agents):\n",
    "        state_map[i] = [[0] * num_nodes for i in range(num_nodes)]\n",
    "    \n",
    "    finish_count = 0\n",
    "    cost = 0\n",
    "    pre_step = [0]*k_agents\n",
    "    info_clustering = clustering()\n",
    "    reward_sum = 0.0\n",
    "    while finish_count != num_edges:\n",
    "        communication()\n",
    "        cost+=1\n",
    "        for i in range(k_agents):\n",
    "            list_x = []\n",
    "            list_y = []\n",
    "            if target[i]==0:\n",
    "                \n",
    "                pre_step[i] = now_point[i]\n",
    "                action = agent.take_action(np.array(features), state[now_point[i]])\n",
    "                feature_sum = 0\n",
    "                edgelen_sum = 0\n",
    "                #print(action)\n",
    "                #print(features)\n",
    "                for item in state[action]:\n",
    "                    feature_sum += features[item][0]\n",
    "                    edgelen_sum += edge_len[item][action]\n",
    "                feature_sum *= 0.7\n",
    "                edgelen_sum *= 0.3\n",
    "                for index_i in range(len(features)):\n",
    "                    for index_j in range(len(features[index_i])):\n",
    "                        prev_features[index_i][index_j] = features[index_i][index_j]\n",
    "                features[action][0] = feature_sum + edgelen_sum\n",
    "                now_point[i] = action\n",
    "                if(state_map[i][now_point[i]][pre_step[i]] == 0):\n",
    "                    reward = 2\n",
    "                else:\n",
    "                    reward = -(edge_len[now_point[i]][pre_step[i]] * 0.01)\n",
    "                reward_sum += reward \n",
    "                agent.store_transition(np.array(prev_features) , action , reward , np.array(features), False)\n",
    "                agent.update_parameters()\n",
    "                \n",
    "                target[i] = edge_len[now_point[i]][pre_step[i]]/speed[i]\n",
    "            location[i]+=1\n",
    "            draw_flag = 0\n",
    "            while location[i]>=target[i]:\n",
    "                state_map[i][now_point[i]][pre_step[i]] = 1\n",
    "                state_map[i][pre_step[i]][now_point[i]] = 1\n",
    "                history_route[i].append(now_point[i])\n",
    "                if god_map[now_point[i]][pre_step[i]]==0:\n",
    "                    finish_count+=1\n",
    "                    god_map[now_point[i]][pre_step[i]] += 1\n",
    "                    god_map[pre_step[i]][now_point[i]] += 1\n",
    "\n",
    "                if(draw_flag == 0):\n",
    "                    pre_x = ((location[i]-1)/target[i])*nodes[now_point[i]][1] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][1]\n",
    "                    pre_y = ((location[i]-1)/target[i])*nodes[now_point[i]][2] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][2]\n",
    "                    now_x = nodes[now_point[i]][1] \n",
    "                    now_y = nodes[now_point[i]][2] \n",
    "                    list_x.append([pre_x, now_x])\n",
    "                    list_y.append([pre_y, now_y])\n",
    "                else:\n",
    "                    pre_x = nodes[pre_step[i]][1]\n",
    "                    pre_y = nodes[pre_step[i]][2] \n",
    "                    now_x = nodes[now_point[i]][1] \n",
    "                    now_y = nodes[now_point[i]][2] \n",
    "                    list_x.append([pre_x, now_x])\n",
    "                    list_y.append([pre_y, now_y])\n",
    "\n",
    "                pre_step[i] = now_point[i]\n",
    "                action = agent.take_action(np.array(features), state[now_point[i]])\n",
    "                feature_sum = 0\n",
    "                edgelen_sum = 0\n",
    "                print(action)\n",
    "                #print(features)\n",
    "                for item in state[action]:\n",
    "                    feature_sum += features[item][0]\n",
    "                    edgelen_sum += edge_len[item][action]\n",
    "                feature_sum *= 0.7\n",
    "                edgelen_sum *= 0.3\n",
    "                for index_i in range(len(features)):\n",
    "                    for index_j in range(len(features[index_i])):\n",
    "                        prev_features[index_i][index_j] = features[index_i][index_j]\n",
    "                features[action][0] = feature_sum + edgelen_sum\n",
    "                now_point[i] = action\n",
    "                if(state_map[i][now_point[i]][pre_step[i]] == 0):\n",
    "                    reward = 2\n",
    "                else:\n",
    "                    reward = -(edge_len[now_point[i]][pre_step[i]] * 0.01)\n",
    "                reward_sum += reward \n",
    "                agent.store_transition(np.array(prev_features) , action , reward , np.array(features), False)\n",
    "                agent.update_parameters()\n",
    "                \n",
    "                location[i] = location[i]-target[i]\n",
    "                target[i] = edge_len[now_point[i]][pre_step[i]]/speed[i]\n",
    "                if i in on_nodes[pre_step[i]]:\n",
    "                    on_nodes[pre_step[i]].remove(i)\n",
    "                draw_flag = 1\n",
    "            if (draw_flag == 1):\n",
    "                pre_x = nodes[pre_step[i]][1] \n",
    "                pre_y = nodes[pre_step[i]][2]\n",
    "                now_x = ((location[i])/target[i])*nodes[now_point[i]][1] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][1]\n",
    "                now_y = ((location[i])/target[i])*nodes[now_point[i]][2] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][2]\n",
    "                list_x.append([pre_x, now_x])\n",
    "                list_y.append([pre_y, now_y])\n",
    "                x_agent[i].append(list_x)\n",
    "                y_agent[i].append(list_y)\n",
    "            else:\n",
    "                pre_x = ((location[i]-1)/target[i])*nodes[now_point[i]][1] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][1]\n",
    "                pre_y = ((location[i]-1)/target[i])*nodes[now_point[i]][2] + ((target[i] - (location[i]-1))/target[i])*nodes[pre_step[i]][2]\n",
    "                now_x = ((location[i])/target[i])*nodes[now_point[i]][1] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][1]\n",
    "                now_y = ((location[i])/target[i])*nodes[now_point[i]][2] + ((target[i] - location[i])/target[i])*nodes[pre_step[i]][2]\n",
    "                x_agent[i].append([pre_x, now_x])\n",
    "                y_agent[i].append([pre_y, now_y])\n",
    "\n",
    "            if (location[i]/target[i]) > 0.5:\n",
    "                if i not in on_nodes[now_point[i]]:\n",
    "                    on_nodes[now_point[i]].append(i)\n",
    "            else:\n",
    "                if i not in on_nodes[pre_step[i]]:\n",
    "                    on_nodes[pre_step[i]].append(i)\n",
    "    reward_history.append(reward_sum)\n",
    "    if e  % 50 == 0:\n",
    "        print(reward_sum)\n",
    "    if e > 0 and e % 20 == 0:\n",
    "        agent.update_target_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  390 ticks\n"
     ]
    }
   ],
   "source": [
    "print('cost: ', cost, 'ticks')\n",
    "#print(history_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "x = []\n",
    "y = []\n",
    "for i in range(num_nodes):\n",
    "    node1 = i\n",
    "    for node2 in state[i]:\n",
    "        x.append([nodes[node1][1], nodes[node2][1]])\n",
    "        y.append([nodes[node1][2], nodes[node2][2]])\n",
    "\n",
    "x_1data = []\n",
    "y_1data = []\n",
    "x_2data = []\n",
    "y_2data = []\n",
    "x_3data = []\n",
    "y_3data = []\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 1000)\n",
    "ax.set_ylim(0, 1000)\n",
    "line, = ax.plot(0, 0, color = 'silver')\n",
    "line_1, = ax.plot(0, 0, color='red')\n",
    "line_2, = ax.plot(0, 0, color='black')\n",
    "line_3, = ax.plot(0, 0, color='blue')\n",
    "ball_1 = plt.Circle((5, -5), 18, fc='red')\n",
    "ball_2 = plt.Circle((5, -5), 18, fc='black')\n",
    "ball_3 = plt.Circle((5, -5), 18, fc='blue')\n",
    "def animation_frame(i):\n",
    "    \n",
    "    if i >= 0:\n",
    "        if(i<len(x_agent[0])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[0][i])):\n",
    "                if isinstance(x_agent[0][i][j], list):\n",
    "                    x_1data.append(x_agent[0][i][j])\n",
    "                    y_1data.append(y_agent[0][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_1.center = (x_agent[0][i][j][1], y_agent[0][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_1data.append(x_agent[0][i])\n",
    "                y_1data.append(y_agent[0][i])\n",
    "                ball_1.center = (x_agent[0][i][1], y_agent[0][i][1])\n",
    "\n",
    "            line_1.set_xdata(x_1data)\n",
    "            line_1.set_ydata(y_1data)\n",
    "            \n",
    "            \n",
    "\n",
    "        if(i<len(x_agent[1])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[1][i])):\n",
    "                if isinstance(x_agent[1][i][j], list):\n",
    "                    x_2data.append(x_agent[1][i][j])\n",
    "                    y_2data.append(y_agent[1][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_2.center = (x_agent[1][i][j][1], y_agent[1][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_2data.append(x_agent[1][i])\n",
    "                y_2data.append(y_agent[1][i])\n",
    "                ball_2.center = (x_agent[1][i][1], y_agent[1][i][1])\n",
    "                \n",
    "            line_2.set_xdata(x_2data)\n",
    "            line_2.set_ydata(y_2data)\n",
    "            \n",
    "        if(i<len(x_agent[2])):\n",
    "            islist_flag = 0\n",
    "            for j in range(len(x_agent[2][i])):\n",
    "                if isinstance(x_agent[2][i][j], list):\n",
    "                    x_3data.append(x_agent[2][i][j])\n",
    "                    y_3data.append(y_agent[2][i][j])\n",
    "                    islist_flag = 1\n",
    "                    if j == len(x_agent[0][i])-1:\n",
    "                        ball_3.center = (x_agent[2][i][j][1], y_agent[2][i][j][1])\n",
    "            if(islist_flag == 0):\n",
    "                x_3data.append(x_agent[2][i])\n",
    "                y_3data.append(y_agent[2][i])\n",
    "                ball_3.center = (x_agent[2][i][1], y_agent[2][i][1])\n",
    "\n",
    "            line_3.set_xdata(x_3data)\n",
    "            line_3.set_ydata(y_3data)\n",
    "    \n",
    "    return line_1,line_2,line_3,ball_1,ball_2,ball_3,\n",
    "def init():\n",
    "    line.set_xdata(x)\n",
    "    line.set_ydata(y)\n",
    "    \n",
    "    line_1.set_xdata(x_agent[0][0][0])\n",
    "    line_1.set_ydata(y_agent[0][0][0])\n",
    "    \n",
    "    line_2.set_xdata(x_agent[1][0][0])\n",
    "    line_2.set_ydata(y_agent[1][0][0])\n",
    "    \n",
    "    line_3.set_xdata(x_agent[2][0][0])\n",
    "    line_3.set_ydata(y_agent[2][0][0])\n",
    "    \n",
    "    ball_1.center = (x_agent[0][0][0], y_agent[0][0][0])\n",
    "    ax.add_patch(ball_1)\n",
    "    \n",
    "    ball_2.center = (x_agent[1][0][0], y_agent[1][0][0])\n",
    "    ax.add_patch(ball_2)\n",
    "    \n",
    "    ball_3.center = (x_agent[2][0][0], y_agent[2][0][0])\n",
    "    ax.add_patch(ball_3)\n",
    "    \n",
    "    return line, line_1,line_2,line_3, ball_1,ball_2,ball_3,\n",
    "    \n",
    "animation = FuncAnimation(fig, func=animation_frame, frames=np.arange(-2, len(x_agent[0]), 1), init_func=init, interval=10)\n",
    "plt.show()\n",
    "animation.save('basic_animation2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405 398 396\n"
     ]
    }
   ],
   "source": [
    "print(len(x_1data),len(x_2data),len(x_3data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 3, 1], [3, 0, 2, 4], [3, 4, 1], [0, 1, 2, 4], [0, 2, 3, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
